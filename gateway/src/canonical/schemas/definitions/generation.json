{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "$id": "https://ekailabs.xyz/schemas/definitions/generation/v1.0.0",
  "title": "Generation Parameters",
  "description": "AI model generation control parameters",
  
  "definitions": {
    "generation": {
      "type": "object",
      "properties": {
        "max_tokens": {
          "type": "integer",
          "minimum": 1,
          "maximum": 1000000,
          "description": "Maximum number of tokens to generate"
        },
        "temperature": {
          "type": "number",
          "minimum": 0,
          "maximum": 2,
          "description": "Controls randomness: 0 = deterministic, 2 = very random"
        },
        "top_p": {
          "type": "number",
          "minimum": 0,
          "maximum": 1,
          "description": "Nucleus sampling: only consider tokens with top p probability mass"
        },
        "top_k": {
          "type": "integer",
          "minimum": 1,
          "maximum": 100,
          "description": "Only consider top k most likely tokens"
        },
        "stop": {
          "oneOf": [
            { "type": "string" },
            {
              "type": "array",
              "items": { "type": "string" },
              "maxItems": 64
            }
          ],
          "description": "Sequences where generation should stop"
        },
        "seed": {
          "type": "integer",
          "minimum": 0,
          "description": "Random seed for reproducible generation"
        },
        "frequency_penalty": {
          "type": "number",
          "minimum": -2,
          "maximum": 2,
          "description": "Penalty for frequent tokens (positive = less likely)"
        },
        "presence_penalty": {
          "type": "number",
          "minimum": -2,
          "maximum": 2,
          "description": "Penalty for tokens that have appeared (positive = less likely)"
        },
        "n": {
          "type": "integer",
          "minimum": 1,
          "maximum": 20,
          "description": "Number of completions to generate"
        },
        "logprobs": { 
          "type": "boolean",
          "description": "Whether to return log probabilities"
        },
        "top_logprobs": {
          "type": "integer",
          "minimum": 0,
          "maximum": 5,
          "description": "Number of most likely tokens to return probabilities for"
        },
        "logit_bias": {
          "type": "object",
          "patternProperties": {
            "^\\d+$": {
              "type": "number",
              "minimum": -100,
              "maximum": 100
            }
          },
          "additionalProperties": false,
          "description": "Modify likelihood of specific tokens by token ID"
        },
        "stop_sequences": {
          "type": "array",
          "items": { "type": "string" },
          "maxItems": 64,
          "description": "Alternative to 'stop' parameter for some providers"
        }
      },
      "additionalProperties": false
    },

    "serviceTier": {
      "enum": ["auto", "default", "scale", "flex", "priority", null],
      "description": "Service tier for request prioritization"
    },

    "reasoningEffort": {
      "enum": ["low", "medium", "high"],
      "description": "Amount of reasoning effort to apply"
    },

    "modalities": {
      "type": "array",
      "items": {
        "enum": ["text", "audio"]
      },
      "uniqueItems": true,
      "description": "Output modalities to enable"
    },

    "tier": {
      "enum": ["priority", "standard"],
      "description": "Processing tier"
    }
  }
}