provider: "ollama"
currency: "USD"
unit: "MTok"
models:
  # Ollama runs models locally — all costs are zero.
  # Users may add custom model entries here if needed.
  llama3.3:
    input: 0.00
    output: 0.00
  llama3.2:
    input: 0.00
    output: 0.00
  llama3.1:
    input: 0.00
    output: 0.00
  llama3:
    input: 0.00
    output: 0.00
  gemma3:
    input: 0.00
    output: 0.00
  gemma2:
    input: 0.00
    output: 0.00
  qwen3:
    input: 0.00
    output: 0.00
  qwen2.5-coder:
    input: 0.00
    output: 0.00
  deepseek-r1:
    input: 0.00
    output: 0.00
  deepseek-coder-v2:
    input: 0.00
    output: 0.00
  phi4:
    input: 0.00
    output: 0.00
  phi3:
    input: 0.00
    output: 0.00
  mistral:
    input: 0.00
    output: 0.00
  mixtral:
    input: 0.00
    output: 0.00
  codellama:
    input: 0.00
    output: 0.00
  starcoder2:
    input: 0.00
    output: 0.00
metadata:
  last_updated: "2026-02-03"
  source: "https://ollama.com"
  notes: "Ollama runs models locally. All API costs are zero — hardware costs are borne by the user."
  version: "1.0"
